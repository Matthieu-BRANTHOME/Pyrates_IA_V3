{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyrates IA V3 - Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)  Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Students constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAN_S3 = [\n",
    "    {\"game\" : \"HcN3TGD\", \"id\" : 24, \"group\": \"A\"},\n",
    "    {\"game\" : \"NLTET8y\", \"id\" : 25, \"group\": \"A\"},\n",
    "    {\"game\" : \"6xExMYw\", \"id\" : 26, \"group\": \"A\"},\n",
    "    {\"game\" : \"E7vmemn\", \"id\" : 27, \"group\": \"A\"},\n",
    "    {\"game\" : \"5eKc43c\", \"id\" : 28, \"group\": \"A\"},\n",
    "    {\"game\" : \"DMTs6iy\", \"id\" : 29, \"group\": \"A\"},\n",
    "    {\"game\" : \"eHuZtre\", \"id\" : 30, \"group\": \"A\"},\n",
    "    {\"game\" : \"LahVD8s\", \"id\" : 31, \"group\": \"A\"},\n",
    "    {\"game\" : \"EJSMbPz\", \"id\" : 32, \"group\": \"A\"},\n",
    "    {\"game\" : \"BWgeNTq\", \"id\" : 33, \"group\": \"A\"},\n",
    "    {\"game\" : \"g9AnsLe\", \"id\" : 35, \"group\": \"A\"},\n",
    "    {\"game\" : \"Ee6est8\", \"id\" : 36, \"group\": \"A\"},\n",
    "    {\"game\" : \"vEEvsMa\", \"id\" : 37, \"group\": \"A\"},\n",
    "    {\"game\" : \"1c9tb2d\", \"id\" : 38, \"group\": \"A\"},\n",
    "    {\"game\" : \"BSFagXS\", \"id\" : 40, \"group\": \"A\"},\n",
    "    {\"game\" : \"HNJ75xA\", \"id\" : 41, \"group\": \"A\"},\n",
    "    {\"game\" : \"md7tB97\", \"id\" : 42, \"group\": \"A\"},\n",
    "    {\"game\" : \"NmHW4Ra\", \"id\" : 43, \"group\": \"A\"},\n",
    "    {\"game\" : \"Mw8Es3C\", \"id\" : 44, \"group\": \"A\"},\n",
    "    {\"game\" : \"GBLHCx9\", \"id\" : 45, \"group\": \"A\"},\n",
    "    {\"game\" : \"GHbmTTg\", \"id\" : 46, \"group\": \"A\"},\n",
    "]\n",
    "LAN_S8 = [\n",
    "    {\"game\" : \"KithBLH\", \"id\" : 47, \"group\": \"B\"},\n",
    "    {\"game\" : \"YQhWN2z\", \"id\" : 48, \"group\": \"B\"},\n",
    "    {\"game\" : \"yWr94BN\", \"id\" : 49, \"group\": \"B\"},\n",
    "    {\"game\" : \"CCEnqrs\", \"id\" : 50, \"group\": \"B\"},\n",
    "    {\"game\" : \"CQVmn1P\", \"id\" : 51, \"group\": \"B\"},\n",
    "    {\"game\" : \"rEU8Tiq\", \"id\" : 52, \"group\": \"B\"},\n",
    "    {\"game\" : \"kqQrtAk\", \"id\" : 53, \"group\": \"B\"},\n",
    "    {\"game\" : \"nbfDnDS\", \"id\" : 54, \"group\": \"B\"},\n",
    "    {\"game\" : \"fZPxgSi\", \"id\" : 55, \"group\": \"B\"},\n",
    "    {\"game\" : \"ec7hfL8\", \"id\" : 56, \"group\": \"B\"},\n",
    "    {\"game\" : \"jN7VfTE\", \"id\" : 57, \"group\": \"B\"},\n",
    "    {\"game\" : \"WX54QGZ\", \"id\" : 58, \"group\": \"B\"},\n",
    "    {\"game\" : \"FPu7xpq\", \"id\" : 59, \"group\": \"B\"},\n",
    "    {\"game\" : \"MPXWevd\", \"id\" : 60, \"group\": \"B\"},\n",
    "    {\"game\" : \"uDsYtAY\", \"id\" : 61, \"group\": \"B\"},\n",
    "    {\"game\" : \"1PxBxAu\", \"id\" : 62, \"group\": \"B\"},\n",
    "    {\"game\" : \"RC1k6P6\", \"id\" : 63, \"group\": \"B\"},\n",
    "    {\"game\" : \"aCq8cYG\", \"id\" : 64, \"group\": \"B\"},\n",
    "    {\"game\" : \"ZL2TGp4\", \"id\" : 65, \"group\": \"B\"},\n",
    "    {\"game\" : \"5p4fx4Y\", \"id\" : 66, \"group\": \"B\"},\n",
    "    {\"game\" : \"WNmm7gz\", \"id\" : 67, \"group\": \"B\"},\n",
    "    {\"game\" : \"Tb7cjXu\", \"id\" : 68, \"group\": \"B\"}\n",
    "]\n",
    "LAN_S10 = [\n",
    "    {\"game\" : \"mqDmUa3\", \"id\" : 1, \"group\": \"A\"},\n",
    "    {\"game\" : \"GcmQWAa\", \"id\" : 2, \"group\": \"A\"},\n",
    "    {\"game\" : \"8hYqYSG\", \"id\" : 3, \"group\": \"A\"},\n",
    "    {\"game\" : \"XdF2sz6\", \"id\" : 4, \"group\": \"A\"},\n",
    "    {\"game\" : \"Rj6mATf\", \"id\" : 5, \"group\": \"A\"},\n",
    "    {\"game\" : \"nddvPEB\", \"id\" : 6, \"group\": \"A\"},\n",
    "    {\"game\" : \"rtaygH1\", \"id\" : 7, \"group\": \"A\"},\n",
    "    {\"game\" : \"7LRuReQ\", \"id\" : 8, \"group\": \"A\"},\n",
    "    {\"game\" : \"Q3kVGXG\", \"id\" : 9, \"group\": \"A\"},\n",
    "    {\"game\" : \"BxHq3Cn\", \"id\" : 10, \"group\": \"A\"},\n",
    "    {\"game\" : \"Y18BWBS\", \"id\" : 11, \"group\": \"A\"},\n",
    "    {\"game\" : \"8uynbDg\", \"id\" : 12, \"group\": \"A\"},\n",
    "    {\"game\" : \"XPnMMcz\", \"id\" : 13, \"group\": \"B\"},\n",
    "    {\"game\" : \"MtmK4TN\", \"id\" : 14, \"group\": \"B\"},\n",
    "    {\"game\" : \"uXCjh6E\", \"id\" : 15, \"group\": \"B\"},\n",
    "    {\"game\" : \"BmfYK7Q\", \"id\" : 16, \"group\": \"B\"},\n",
    "    {\"game\" : \"JEH4PPH\", \"id\" : 17, \"group\": \"B\"},\n",
    "    {\"game\" : \"kitHifp\", \"id\" : 18, \"group\": \"B\"},\n",
    "    {\"game\" : \"7bfEHcG\", \"id\" : 19, \"group\": \"B\"},\n",
    "    {\"game\" : \"GWDnaUv\", \"id\" : 20, \"group\": \"B\"},\n",
    "    {\"game\" : \"dFjxgLF\", \"id\" : 21, \"group\": \"B\"},\n",
    "    {\"game\" : \"smeJddf\", \"id\" : 22, \"group\": \"B\"},\n",
    "    {\"game\" : \"NNAFyqZ\", \"id\" : 23, \"group\": \"B\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Row data constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Column keys ----\n",
    "ID_DATA_KEY = \"_id\"\n",
    "TYPE_DATA_KEY = \"_type\"\n",
    "LEVEL_DATA_KEY = \"_level\"\t\n",
    "STUDENT_DATA_KEY = \"_student\"\t\n",
    "DATE_DATA_KEY = \"_date\"\n",
    "OBJECT_ID_DATA_KEY = \"_object_id\"\n",
    "GAME_ERROR_REASON_DATA_KEY = \"_game_error_reason\"\n",
    "LOST_LEVEL_DATA_KEY = \"_lost_level\"\n",
    "GAME_PROGRESSION_DATA_KEY = \"_game_progression\"\n",
    "DURATION_DATA_KEY = \"_duration\"\n",
    "EXTRA_LINES_NUMBER_DATA_KEY =\"_extra_lines_number\"\n",
    "ERROR_DATA_KEY =\"_error\"\n",
    "GAME_TIME_DATA_KEY =\"_game_time\"\n",
    "STOPPED_LINE_DATA_KEY =\"_stopped_line\"\n",
    "EXECUTION_SPEED_MULTIPLIER_DATA_KEY =\"_execution_speed_multiplier\"\n",
    "EXECUTION_SPEED_CHANGED_DATA_KEY =\"_execution_speed_changed\"\n",
    "CODE_DATA_KEY = \"_code\"\n",
    "HELP_PREDICTED_VALUE_DATA_KEY = \"_help_predicted_value\"\n",
    "HELP_PREDICTION_CONFIDENCE_DATA_KEY = \"_help_prediction_confidence\"\n",
    "\n",
    "\n",
    "INTERACTION_DATA_KEYS = [\n",
    "    ID_DATA_KEY,\n",
    "    TYPE_DATA_KEY ,\n",
    "    LEVEL_DATA_KEY ,\n",
    "    STUDENT_DATA_KEY ,\n",
    "    DATE_DATA_KEY ,\n",
    "    OBJECT_ID_DATA_KEY ,\n",
    "    GAME_ERROR_REASON_DATA_KEY ,\n",
    "    LOST_LEVEL_DATA_KEY ,\n",
    "    GAME_PROGRESSION_DATA_KEY ,\n",
    "    DURATION_DATA_KEY ,\n",
    "    EXTRA_LINES_NUMBER_DATA_KEY ,\n",
    "    ERROR_DATA_KEY ,\n",
    "    GAME_TIME_DATA_KEY ,\n",
    "    STOPPED_LINE_DATA_KEY ,\n",
    "    EXECUTION_SPEED_MULTIPLIER_DATA_KEY ,\n",
    "    EXECUTION_SPEED_CHANGED_DATA_KEY ,\n",
    "    CODE_DATA_KEY,\n",
    "    HELP_PREDICTED_VALUE_DATA_KEY,\n",
    "    HELP_PREDICTION_CONFIDENCE_DATA_KEY\n",
    "]\n",
    "\n",
    "# ---- Column values ----\n",
    "\n",
    "# _type values \n",
    "ASKED_TYPE =\"https://py-rates.org/xAPI/verbs/asked\"\n",
    "CHANGED_TYPE = \"https://py-rates.org/xAPI/verbs/changed\"\n",
    "COMPLETED_TYPE = \"https://py-rates.org/xAPI/verbs/completed\"\n",
    "CONSULTED_TYPE = \"https://py-rates.org/xAPI/verbs/consulted\"\n",
    "COPIED_TYPE = \"https://py-rates.org/xAPI/verbs/copied\"\n",
    "LAUNCHED_TYPE =\"https://py-rates.org/xAPI/verbs/launched\"\n",
    "LEAVED_TYPE =\"https://py-rates.org/xAPI/verbs/leaved\"\n",
    "PASTED_TYPE = \"https://py-rates.org/xAPI/verbs/pasted\"\n",
    "RECEIVED_TYPE = \"https://py-rates.org/xAPI/verbs/received\"\n",
    "RESTARTED_TYPE = \"https://py-rates.org/xAPI/verbs/restarted\"\n",
    "RESUMED_TYPE = \"https://py-rates.org/xAPI/verbs/resumed\"\n",
    "STARTED_TYPE = \"https://py-rates.org/xAPI/verbs/started\"\n",
    "\n",
    "# _level values\n",
    "LEVEL_1 = \"Level1\"\n",
    "LEVEL_2 = \"Level2\"\n",
    "LEVEL_3 = \"Level3\"\n",
    "LEVEL_4 = \"Level4\"\n",
    "LEVEL_5 = \"Level5\"\n",
    "LEVEL_6 = \"Level6\"\n",
    "LEVEL_7 = \"Level7\"\n",
    "LEVEL_8 = \"Level8\"\n",
    "LEVELS_KEYS = [LEVEL_1,LEVEL_2,LEVEL_3,LEVEL_4,LEVEL_5,LEVEL_6,LEVEL_7,LEVEL_8]\n",
    "LEVEL_MAPPING = {\n",
    "    LEVEL_1: 1,\n",
    "    LEVEL_2: 2,\n",
    "    LEVEL_3: 3,\n",
    "    LEVEL_4: 4,\n",
    "    LEVEL_5: 5,\n",
    "    LEVEL_6: 6,\n",
    "    LEVEL_7: 7,\n",
    "    LEVEL_8: 8\n",
    "}\n",
    "\n",
    "# _object_id values\n",
    "FULLY_EXECUTED_PROGRAM = \"https://py-rates.org/xAPI/activities/programs/fully-executed\"\n",
    "SYNTACTIC_ERROR_PROGRAM = \"https://py-rates.org/xAPI/activities/programs/syntactic-error\"\n",
    "GAME_ERROR_PROGRAM = \"https://py-rates.org/xAPI/activities/programs/game-error\"\n",
    "USER_STOPPED_PROGRAM = \"https://py-rates.org/xAPI/activities/programs/user-stopped\"\n",
    "LEVEL_COMPLETED_PROGRAM = \"https://py-rates.org/xAPI/activities/programs/level-completed\"\n",
    "SEMANTIC_ERROR_PROGRAM = \"https://py-rates.org/xAPI/activities/programs/semantic-error\"\n",
    "TOO_MANY_LINES_PROGRAM = \"https://py-rates.org/xAPI/activities/programs/too-many-lines\"\n",
    "LEVEL_LOST_PROGRAM = \"https://py-rates.org/xAPI/activities/programs/level-lost\"\n",
    "\n",
    "CODE_EDITOR_CONTENT =\"https://py-rates.org/xAPI/activities/contents/code-editor\"\n",
    "CONTROL_FUNCTIONS_CONTENT =\"https://py-rates.org/xAPI/activities/contents/control-functions\"\n",
    "HELP_CONTENT =\"https://py-rates.org/xAPI/activities/contents/help-content\"\n",
    "\n",
    "STARTUP_OPERATION_CONTENT= \"https://py-rates.org/xAPI/activities/contents/startup-operation\"\n",
    "STARTUP_GOAL_CONTENT= \"https://py-rates.org/xAPI/activities/contents/startup-goal\"\n",
    "STARTUP_SAVE_CONTENT= \"https://py-rates.org/xAPI/activities/contents/startup-save\"\n",
    "\n",
    "BASE_PROGRAM_CONTENT =\"https://py-rates.org/xAPI/activities/contents/base-program\"\n",
    "BASE_ERROR_CONTENT =\"https://py-rates.org/xAPI/activities/contents/base-error\"\n",
    "BASE_STRUCTURE_CONTENT =\"https://py-rates.org/xAPI/activities/contents/base-structure\"\n",
    "BASE_COMMENT_CONTENT =\"https://py-rates.org/xAPI/activities/contents/base-comment\"\n",
    "\n",
    "VAR_CREATION_CONTENT =\"https://py-rates.org/xAPI/activities/contents/var-creation\"\n",
    "VAR_USAGE_CONTENT =\"https://py-rates.org/xAPI/activities/contents/var-usage\"\n",
    "VAR_MODIFICATION_CONTENT =\"https://py-rates.org/xAPI/activities/contents/var-modification\"\n",
    "VAR_TYPE_CONTENT =\"https://py-rates.org/xAPI/activities/contents/var-type\"\n",
    "\n",
    "CONDI_1BRAN_CONTENT =\"https://py-rates.org/xAPI/activities/contents/condi-1bran\"\n",
    "CONDI_2BRAN_CONTENT =\"https://py-rates.org/xAPI/activities/contents/condi-2bran\"\n",
    "CONDI_3BRAN_CONTENT =\"https://py-rates.org/xAPI/activities/contents/condi-3bran\"\n",
    "\n",
    "FOR_SIMPLE_CONTENT =\"https://py-rates.org/xAPI/activities/contents/for-simple\"\n",
    "FOR_COUNTER_1_CONTENT =\"https://py-rates.org/xAPI/activities/contents/for-counter-0\"\n",
    "FOR_COUNTER_N_CONTENT =\"https://py-rates.org/xAPI/activities/contents/for-counter-n\"\n",
    "\n",
    "WHILE_SUB_CONTENT =\"https://py-rates.org/xAPI/activities/contents/while-simple\"\n",
    "\n",
    "HELP =\"https://py-rates.org/xAPI/activities/help\"\n",
    "ASK_TEACHER_HELP =\"https://py-rates.org/xAPI/activities/helps/ask-teacher\"\n",
    "CONTROL_HELP =\"https://py-rates.org/xAPI/activities/helps/control\"\n",
    "IMPLEMENTATION_HELP =\"https://py-rates.org/xAPI/activities/helps/implementation\"\n",
    "NOTION_HELP =\"https://py-rates.org/xAPI/activities/helps/notion\"\n",
    "SOLUTION_HELP =\"https://py-rates.org/xAPI/activities/helps/solution\"\n",
    "TEACHER_HELP =\"https://py-rates.org/xAPI/activities/helps/teacher\"\n",
    "\n",
    "# Content type\n",
    "STARTUP_CONTENT = \"startup-content\"\n",
    "BASE_CONTENT = \"base-content\"\n",
    "VAR_CONTENT = \"var-content\"\n",
    "CONDI_CONTENT = \"condi-content\"\n",
    "FOR_CONTENT = \"for-content\"\n",
    "WHILE_CONTENT = \"while-content\"\n",
    "\n",
    "# _game_error_reason\n",
    "WALK_LOCATION_GAME_ERROR = \"walk-location\"\n",
    "READ_MESSAGE_LOCATION_GAME_ERROR =\"read-message-location\"\n",
    "FUNCTION_PARAMETERS_GAME_ERROR =\"function_parameters\"\n",
    "NOT_ALLOWED_FUNCTION_GAME_ERROR =\"not-allowed-function\"\n",
    "OPEN_CHEST_LOCATION_GAME_ERROR =\"open-chest-location\"\n",
    "OPEN_CHEST_KEY_GAME_ERROR =\"open-chest-key\"\n",
    "\n",
    "# _lost_level\n",
    "SPIKES_TOUCH_LOST_LEVEL = \"spikes-touch\"\n",
    "BARREL_EXPLOSION_LOST_LEVEL =\"barrel-explosion\"\n",
    "PIRATE_SHOT_LOST_LEVEL =\"pirate-shot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-test and post-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_ROW = \"_code\"\n",
    "QA_ROW = \"_QA\"\n",
    "QB_ROW = \"_QB\"\n",
    "Q1_ROW = \"_Q1\"\n",
    "Q2_ROW = \"_Q2\"\n",
    "Q3_ROW = \"_Q3\"\n",
    "Q4_ROW = \"_Q4\"\n",
    "Q5_ROW = \"_Q5\"\n",
    "Q6_ROW = \"_Q6\"\n",
    "Q7_ROW = \"_Q7\"\n",
    "Q8_ROW = \"_Q8\"\n",
    "Q9_ROW = \"_Q9\"\n",
    "\n",
    "VAR_NOTION_QUESTIONS = [Q1_ROW, Q4_ROW, Q7_ROW]\n",
    "FOR_LOOP_NOTION_QUESTIONS =  [Q2_ROW, Q5_ROW, Q8_ROW]\n",
    "COND_NOTION_QUESTIONS = [Q3_ROW, Q6_ROW, Q9_ROW]\n",
    "\n",
    "CHOICE_QUESTIONS = [\n",
    "    Q1_ROW,\n",
    "    Q2_ROW,\n",
    "    Q3_ROW,\n",
    "    Q4_ROW,\n",
    "    Q5_ROW,\n",
    "    Q6_ROW,\n",
    "    Q7_ROW,\n",
    "    Q8_ROW,\n",
    "    Q9_ROW,\n",
    "]\n",
    "\n",
    "NUMERIC_QUESTIONS = [QA_ROW,QB_ROW]\n",
    "\n",
    "PRE_TEST_DATA_KEYS = [CODE_ROW] + CHOICE_QUESTIONS\n",
    "\n",
    "POST_TEST_DATA_KEYS = [CODE_ROW] + CHOICE_QUESTIONS + NUMERIC_QUESTIONS\n",
    "\n",
    "ANSWERS_SCORES_BASIC = {\n",
    "    Q1_ROW : {\n",
    "        \"A\": 0,\n",
    "        \"B\": 0,\n",
    "        \"C\": 0,\n",
    "        \"D\": 1,\n",
    "        \"E\": 0,\n",
    "    },\n",
    "    Q2_ROW : {\n",
    "        \"A\": 0,\n",
    "        \"B\": 0,\n",
    "        \"C\": 0,\n",
    "        \"D\": 0,\n",
    "        \"E\": 1,\n",
    "    },\n",
    "    Q3_ROW : {\n",
    "        \"A\": 0,\n",
    "        \"B\": 0,\n",
    "        \"C\": 0,\n",
    "        \"D\": 0,\n",
    "        \"E\": 1,\n",
    "    },\n",
    "    Q4_ROW : {\n",
    "        \"A\": 0,\n",
    "        \"B\": 0,\n",
    "        \"C\": 0,\n",
    "        \"D\": 0,\n",
    "        \"E\": 1,\n",
    "    },\n",
    "    Q5_ROW : {\n",
    "        \"A\": 1,\n",
    "        \"B\": 0,\n",
    "        \"C\": 0,\n",
    "        \"D\": 0,\n",
    "        \"E\": 0,\n",
    "    },\n",
    "    Q6_ROW : {\n",
    "        \"A\": 1,\n",
    "        \"B\": 0,\n",
    "        \"C\": 0,\n",
    "        \"D\": 0,\n",
    "        \"E\": 0,\n",
    "    },\n",
    "    Q7_ROW : {\n",
    "        \"A\": 0,\n",
    "        \"B\": 1,\n",
    "        \"C\": 0,\n",
    "        \"D\": 0,\n",
    "        \"E\": 0,\n",
    "    },\n",
    "    Q8_ROW : {\n",
    "        \"A\": 0,\n",
    "        \"B\": 0,\n",
    "        \"C\": 0,\n",
    "        \"D\": 1,\n",
    "        \"E\": 0,\n",
    "    },\n",
    "    Q9_ROW : {\n",
    "        \"A\": 0,\n",
    "        \"B\": 0,\n",
    "        \"C\": 0,\n",
    "        \"D\": 1,\n",
    "        \"E\": 0,\n",
    "    },\n",
    "\n",
    "}\n",
    "ANSWERS_SCORES_GRADUATED = {\n",
    "    Q1_ROW : {\n",
    "        \"A\": 0,\n",
    "        \"B\": 1,\n",
    "        \"C\": 1,\n",
    "        \"D\": 3,\n",
    "        \"E\": 2,\n",
    "    },\n",
    "    Q2_ROW : {\n",
    "        \"A\": 0,\n",
    "        \"B\": 0,\n",
    "        \"C\": 0,\n",
    "        \"D\": 1,\n",
    "        \"E\": 3,\n",
    "    },\n",
    "    Q3_ROW : {\n",
    "        \"A\": 1,\n",
    "        \"B\": 2,\n",
    "        \"C\": 0,\n",
    "        \"D\": 1,\n",
    "        \"E\": 3,\n",
    "    },\n",
    "    Q4_ROW : {\n",
    "        \"A\": 0,\n",
    "        \"B\": 0,\n",
    "        \"C\": 1,\n",
    "        \"D\": 1,\n",
    "        \"E\": 3,\n",
    "    },\n",
    "    Q5_ROW : {\n",
    "        \"A\": 3,\n",
    "        \"B\": 0,\n",
    "        \"C\": 2,\n",
    "        \"D\": 0,\n",
    "        \"E\": 2,\n",
    "    },\n",
    "    Q6_ROW : {\n",
    "        \"A\": 3,\n",
    "        \"B\": 0,\n",
    "        \"C\": 1,\n",
    "        \"D\": 1,\n",
    "        \"E\": 0,\n",
    "    },\n",
    "    Q7_ROW : {\n",
    "        \"A\": 0,\n",
    "        \"B\": 3,\n",
    "        \"C\": 1,\n",
    "        \"D\": 0,\n",
    "        \"E\": 1,\n",
    "    },\n",
    "    Q8_ROW : {\n",
    "        \"A\": 0,\n",
    "        \"B\": 1,\n",
    "        \"C\": 0,\n",
    "        \"D\": 3,\n",
    "        \"E\": 2,\n",
    "    },\n",
    "    Q9_ROW : {\n",
    "        \"A\": 0,\n",
    "        \"B\": 0,\n",
    "        \"C\": 0,\n",
    "        \"D\": 3,\n",
    "        \"E\": 1,\n",
    "    },\n",
    "}\n",
    "ANSWERS_SCORES = ANSWERS_SCORES_GRADUATED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Data fetching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interaction data exportation from LRS : Learning locker export configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#   \"_id\": 1,\n",
    "#   \"_stopped_line\": \"$statement.result.extensions.https://py-rates&46;org/xAPI/extensions/stopped-line\",\n",
    "#   \"_level\": \"$statement.context.contextActivities.other.definition.name.en-US\",\n",
    "#   \"_lost_level\": \"$statement.result.extensions.https://py-rates&46;org/xAPI/extensions/level-lost-reason\",\n",
    "#   \"_error\": \"$statement.result.extensions.https://py-rates&46;org/xAPI/extensions/error\",\n",
    "#   \"_game_error_reason\": \"$statement.result.extensions.https://py-rates&46;org/xAPI/extensions/game-error-reason\",\n",
    "#   \"_code\": \"$statement.object.definition.extensions.https://py-rates&46;org/xAPI/extensions/code\",\n",
    "#   \"_game_progression\": \"$statement.result.extensions.https://py-rates&46;org/xAPI/extensions/progression\",\n",
    "#   \"_date\": \"$statement.timestamp\",\n",
    "#   \"_duration\": \"$statement.result.duration\",\n",
    "#   \"_execution_speed_changed\": \"$statement.object.definition.extensions.https://py-rates&46;org/xAPI/extensions/execution-speed-multiplier\",\n",
    "#   \"_extra_lines_number\": \"$statement.result.extensions.https://py-rates&46;org/xAPI/extensions/extra-lines-number\",\n",
    "#   \"_type\": \"$statement.verb.id\",\n",
    "#   \"_game_time\": \"$statement.context.extensions.https://py-rates&46;org/xAPI/extensions/game-time\",\n",
    "#   \"_object_id\": \"$statement.object.id\",\n",
    "#   \"_student\": \"$statement.actor.account.name\",\n",
    "#   \"_execution_speed_multiplier\": \"$statement.result.extensions.https://py-rates&46;org/xAPI/extensions/execution-speed-multiplier\",\n",
    "#   \"_help_predicted_value\" : \"$statement.context.extensions.https://py-rates&46;org/xAPI/extensions/predicted-value\",\n",
    "#   \"_help_prediction_confidence\" : \"$statement.context.extensions.https://py-rates&46;org/xAPI/extensions/prediction-confidence\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw cvs file from LRS to Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from session 1\n",
    "interaction_data_s1 = pd.read_csv(\"data/raw_data_session_1.csv\",header = 0, quotechar=\"\\\"\")\n",
    "\n",
    "# Reorder columns\n",
    "interaction_data_s1=interaction_data_s1[INTERACTION_DATA_KEYS]\n",
    "\n",
    "# Delete lists extra characters\n",
    "interaction_data_s1[LEVEL_DATA_KEY] = interaction_data_s1[LEVEL_DATA_KEY].str.replace('\\[\\\"',\"\",regex=True)\n",
    "interaction_data_s1[LEVEL_DATA_KEY] = interaction_data_s1[LEVEL_DATA_KEY].str.replace('\\\"\\]',\"\",regex=True)\n",
    "\n",
    "interaction_data_s1[LEVEL_DATA_KEY] = interaction_data_s1[LEVEL_DATA_KEY].str.replace('Level ','Level',regex=True)\n",
    "\n",
    "# Add zero value on some unassigned _game_progression\n",
    "cond = (interaction_data_s1[OBJECT_ID_DATA_KEY].isin([FULLY_EXECUTED_PROGRAM, USER_STOPPED_PROGRAM])) & (interaction_data_s1[GAME_PROGRESSION_DATA_KEY].isna())\n",
    "interaction_data_s1[GAME_PROGRESSION_DATA_KEY].mask(cond ,0, inplace=True)\n",
    "\n",
    "# Load data from session 2\n",
    "interaction_data_s2 = pd.read_csv(\"data/raw_data_session_2.csv\",header = 0, quotechar=\"\\\"\")\n",
    "\n",
    "# Reorder columns\n",
    "interaction_data_s2=interaction_data_s2[INTERACTION_DATA_KEYS]\n",
    "\n",
    "# Delete lists extra characters\n",
    "interaction_data_s2[LEVEL_DATA_KEY] = interaction_data_s2[LEVEL_DATA_KEY].str.replace('Level ','Level',regex=True)\n",
    "\n",
    "# Add zero value on some unassigned _game_progression\n",
    "cond = (interaction_data_s2[OBJECT_ID_DATA_KEY].isin([FULLY_EXECUTED_PROGRAM, USER_STOPPED_PROGRAM])) & (interaction_data_s2[GAME_PROGRESSION_DATA_KEY].isna())\n",
    "interaction_data_s2[GAME_PROGRESSION_DATA_KEY].mask(cond ,0, inplace=True)\n",
    "\n",
    "interaction_data = pd.concat([interaction_data_s1, interaction_data_s2], axis=0, ignore_index=True)\n",
    "\n",
    "# Load data form pre-test\n",
    "pre_test_data  = pd.read_excel(\"data/raw_data_pre-test.xlsx\")\n",
    "# Select columns\n",
    "pre_test_data=pre_test_data[PRE_TEST_DATA_KEYS]\n",
    "#pre_test_data.head(20)\n",
    "\n",
    "# Load data form post-test\n",
    "post_test_data  = pd.read_excel(\"data/raw_data_post-test.xlsx\")\n",
    "# Select columns\n",
    "post_test_data=post_test_data[POST_TEST_DATA_KEYS]\n",
    "#post_test_data.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Data filtration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students : 55\n",
      "Number of interaction traces : 19399\n"
     ]
    }
   ],
   "source": [
    "# Keep experimentation data from date\n",
    "START_XP_DATE = \"2024-09-29T23:59:59.000+02:00\"\n",
    "END_XP_DATE = \"2024-10-08T23:59:59.000+02:00\"\n",
    "interaction_data = interaction_data.loc[interaction_data[DATE_DATA_KEY].between(START_XP_DATE,END_XP_DATE)]\n",
    "\n",
    "# Keep only the data from the students of the experimentation\n",
    "XP_STUDENTS_GAME =  [student[\"game\"] for student in LAN_S3] + [student[\"game\"] for student in LAN_S8] + [student[\"game\"] for student in LAN_S10]\n",
    "\n",
    "# Delete the outliers : student with huge previous Python experience or absent in one session\n",
    "OUTLIERS_PREVIOUS_XP_GAME = [\"YQhWN2z\"]\n",
    "OUTLIERS_ABSENT_GAME = [\"NLTET8y\",\"E7vmemn\",\"EJSMbPz\",\"BSFagXS\",\"GHbmTTg\",\"jN7VfTE\", \"uDsYtAY\", \"MtmK4TN\", \"GWDnaUv\",\"RC1k6P6\"]\n",
    "OUTLIERS_GAME = OUTLIERS_PREVIOUS_XP_GAME + OUTLIERS_ABSENT_GAME\n",
    "\n",
    "# List the outliers id\n",
    "OUTLIERS_ID = []\n",
    "for student in LAN_S3+LAN_S8+LAN_S10 :\n",
    "    if(student[\"game\"] in OUTLIERS_GAME):\n",
    "        OUTLIERS_ID.append(student[\"id\"])\n",
    "# List of kept students\n",
    "XP_STUDENTS_GAME = [student for student in XP_STUDENTS_GAME if student not in OUTLIERS_GAME]\n",
    "print(\"Number of students :\", len(XP_STUDENTS_GAME))\n",
    "\n",
    "# Filter of interaction data over students\n",
    "students_interaction_data = interaction_data[interaction_data[STUDENT_DATA_KEY].isin(XP_STUDENTS_GAME)]\n",
    "\n",
    "# Delete outliers\n",
    "students_interaction_data = students_interaction_data[~students_interaction_data[STUDENT_DATA_KEY].isin(OUTLIERS_GAME)]\n",
    "\n",
    "# Delete duplicates (due to technical issues) \n",
    "students_interaction_data = students_interaction_data.drop_duplicates(subset=ID_DATA_KEY, keep='first');\n",
    "\n",
    "print(\"Number of interaction traces :\", len(students_interaction_data))\n",
    "\n",
    "# Export to Excel file for manual checking\n",
    "# students_interaction_data.to_excel(\"data/cleaned_data_interaction.xlsx\")\n",
    "\n",
    "# Simplifying answers in both tests\n",
    "# Columns to modify\n",
    "cols_to_trim = CHOICE_QUESTIONS\n",
    "# Keep only the first character of specified columns\n",
    "pre_test_data[cols_to_trim] = pre_test_data[cols_to_trim].apply(lambda x: x.str[0])\n",
    "post_test_data[cols_to_trim] = post_test_data[cols_to_trim].apply(lambda x: x.str[0])\n",
    "\n",
    "# Export to Excel file for manual checking\n",
    "# pre_test_data.to_excel(\"data/cleaned_data_pre-test.xlsx\")\n",
    "# post_test_data.to_excel(\"data/cleaned_data_post-test.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1) Separation into two groups (A : with tutor / B: without tutor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students in A group : 28\n",
      "Number of students in B group : 27\n"
     ]
    }
   ],
   "source": [
    "# Keep only the data from the students of the A group\n",
    "XP_A_STUDENTS_GAME =  [student[\"game\"] for student in LAN_S3 if student[\"group\"] == \"A\"] \\\n",
    "    + [student[\"game\"] for student in LAN_S8 if student[\"group\"] == \"A\"] \\\n",
    "    + [student[\"game\"] for student in LAN_S10 if student[\"group\"] == \"A\"]\n",
    "\n",
    "XP_A_STUDENTS_GAME = [student for student in XP_A_STUDENTS_GAME if student not in OUTLIERS_GAME]\n",
    "\n",
    "print(\"Number of students in A group :\", len(XP_A_STUDENTS_GAME))\n",
    "students_A_interaction_data = students_interaction_data[students_interaction_data[STUDENT_DATA_KEY].isin(XP_A_STUDENTS_GAME)]\n",
    "\n",
    "# Keep only the data from the students of the B group\n",
    "XP_B_STUDENTS_GAME =  [student[\"game\"] for student in LAN_S3 if student[\"group\"] == \"B\"] \\\n",
    "    + [student[\"game\"] for student in LAN_S8 if student[\"group\"] == \"B\"] \\\n",
    "    + [student[\"game\"] for student in LAN_S10 if student[\"group\"] == \"B\"]\n",
    "\n",
    "XP_B_STUDENTS_GAME = [student for student in XP_B_STUDENTS_GAME if student not in OUTLIERS_GAME]\n",
    "\n",
    "print(\"Number of students in B group :\", len(XP_B_STUDENTS_GAME))\n",
    "students_B_interaction_data = students_interaction_data[students_interaction_data[STUDENT_DATA_KEY].isin(XP_B_STUDENTS_GAME)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of group A pre-test : 28\n",
      "Number of group A post-test : 28\n",
      "Number of group B pre-test : 27\n",
      "Number of group B post-test : 27\n"
     ]
    }
   ],
   "source": [
    "# Keep only the data from the students of the A group\n",
    "XP_A_STUDENTS_ID = [student[\"id\"] for student in LAN_S3 if student[\"group\"] == \"A\"] \\\n",
    "    + [student[\"id\"] for student in LAN_S8 if student[\"group\"] == \"A\"] \\\n",
    "    + [student[\"id\"] for student in LAN_S10 if student[\"group\"] == \"A\"]\n",
    "\n",
    "XP_A_STUDENTS_ID = [student for student in XP_A_STUDENTS_ID if student not in OUTLIERS_ID]\n",
    "\n",
    "students_A_pre_test_data = pre_test_data[pre_test_data[CODE_ROW].isin(XP_A_STUDENTS_ID)]\n",
    "students_A_post_test_data = post_test_data[post_test_data[CODE_ROW].isin(XP_A_STUDENTS_ID)]\n",
    "\n",
    "print(f\"Number of group A pre-test : {len(students_A_pre_test_data)}\")\n",
    "print(f\"Number of group A post-test : {len(students_A_post_test_data)}\")\n",
    "\n",
    "# Keep only the data from the students of the B group\n",
    "XP_B_STUDENTS_ID =  [student[\"id\"] for student in LAN_S3 if student[\"group\"] == \"B\"] \\\n",
    "    + [student[\"id\"] for student in LAN_S8 if student[\"group\"] == \"B\"] \\\n",
    "    + [student[\"id\"] for student in LAN_S10 if student[\"group\"] == \"B\"]\n",
    "\n",
    "XP_B_STUDENTS_ID = [student for student in XP_B_STUDENTS_ID if student not in OUTLIERS_ID]\n",
    "\n",
    "students_B_pre_test_data = pre_test_data[pre_test_data[CODE_ROW].isin(XP_B_STUDENTS_ID)]\n",
    "students_B_post_test_data = post_test_data[post_test_data[CODE_ROW].isin(XP_B_STUDENTS_ID)]\n",
    "\n",
    "print(f\"Number of group B pre-test : {len(students_B_pre_test_data)}\")\n",
    "print(f\"Number of group B post-test : {len(students_B_post_test_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) Average teachers call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Group - Average teacher calls :1.6071428571428572\n",
      "B Group - Average teacher calls : 2.2962962962962963\n",
      "T-test : p-value = 0.3136203115401371\n",
      "Mann-Whitney U test: p-value = 0.7544091570068345\n",
      "Difference in percentage: 0.30011520737327185\n"
     ]
    }
   ],
   "source": [
    "# Filter the rows where the event type is \"received\" and the object is \"helps/teacher\"\n",
    "teacher_calls_A = students_A_interaction_data[\n",
    "    (students_A_interaction_data[TYPE_DATA_KEY] == RECEIVED_TYPE) &\n",
    "    (students_A_interaction_data[OBJECT_ID_DATA_KEY] == TEACHER_HELP)\n",
    "]\n",
    "\n",
    "# Count the number of teacher calls for each student\n",
    "calls_per_student_A = teacher_calls_A.groupby(STUDENT_DATA_KEY).size()\n",
    "\n",
    "# For students who didn't make any calls, assign 0\n",
    "calls_per_student_A = calls_per_student_A.reindex(XP_A_STUDENTS_GAME, fill_value=0)\n",
    "\n",
    "# Calculate the average number of teacher calls per student\n",
    "average_calls_A = calls_per_student_A.mean()\n",
    "\n",
    "print(\"A Group - Average teacher calls :\"+str(average_calls_A))\n",
    "\n",
    "teacher_calls_B = students_B_interaction_data[\n",
    "    (students_B_interaction_data[TYPE_DATA_KEY] == RECEIVED_TYPE) &\n",
    "    (students_B_interaction_data[OBJECT_ID_DATA_KEY] == TEACHER_HELP)\n",
    "]\n",
    "\n",
    "calls_per_student_B = teacher_calls_B.groupby(STUDENT_DATA_KEY).size()\n",
    "\n",
    "calls_per_student_B = calls_per_student_B.reindex(XP_B_STUDENTS_GAME, fill_value=0)\n",
    "\n",
    "average_calls_B = calls_per_student_B.mean()\n",
    "\n",
    "print(\"B Group - Average teacher calls : \"+str(average_calls_B))\n",
    "\n",
    "# T-test for independent groups \n",
    "t_test = stats.ttest_ind(calls_per_student_A, calls_per_student_B)\n",
    "print(f\"T-test : p-value = {t_test.pvalue}\")\n",
    "\n",
    "# Mann-Whitney U for independent groups\n",
    "mann_whitney_test = stats.mannwhitneyu(calls_per_student_A, calls_per_student_B)\n",
    "print(f\"Mann-Whitney U test: p-value = {mann_whitney_test.pvalue}\")\n",
    "\n",
    "# Difference percentage\n",
    "diff_percent = (average_calls_B - average_calls_A) / average_calls_B\n",
    "print(f\"Difference in percentage: {diff_percent}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3) Average reached level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Group - Average reached level : 6.428571428571429\n",
      "B Group - Average reached level : 5.518518518518518\n",
      "T-test : p-value = 0.06629090834221435\n",
      "Mann-Whitney U test: p-value = 0.09309295830957123\n",
      "Difference in percentage: 0.16490891658676907\n"
     ]
    }
   ],
   "source": [
    "# Filter the rows where _type is \"started\"\n",
    "started_activities_A = students_A_interaction_data[students_A_interaction_data[TYPE_DATA_KEY] == STARTED_TYPE].copy()\n",
    "\n",
    "# Apply the mapping to the _level column (ex \"Level1\" -> 1)\n",
    "started_activities_A.loc[:, 'level_numeric'] = started_activities_A[LEVEL_DATA_KEY].map(LEVEL_MAPPING)\n",
    "\n",
    "# Group by student and find the maximum level reached\n",
    "max_level_per_student_A = started_activities_A.groupby(STUDENT_DATA_KEY)['level_numeric'].max()\n",
    "\n",
    "# Calculate the average of the maximum reached levels\n",
    "average_max_level_A = max_level_per_student_A.mean()\n",
    "\n",
    "print(\"A Group - Average reached level : \"+str(average_max_level_A))\n",
    "\n",
    "started_activities_B = students_B_interaction_data[students_B_interaction_data[TYPE_DATA_KEY] == STARTED_TYPE].copy()\n",
    "\n",
    "# Apply the mapping to the _level column\n",
    "started_activities_B.loc[:, 'level_numeric'] = started_activities_B[LEVEL_DATA_KEY].map(LEVEL_MAPPING)\n",
    "\n",
    "# Group by student and find the maximum level reached\n",
    "max_level_per_student_B = started_activities_B.groupby(STUDENT_DATA_KEY)['level_numeric'].max()\n",
    "\n",
    "# Calculate the average of the maximum levels\n",
    "average_max_level_B = max_level_per_student_B.mean()\n",
    "\n",
    "print(\"B Group - Average reached level : \"+str(average_max_level_B))\n",
    "\n",
    "# T-test for independent groups \n",
    "t_test = stats.ttest_ind(max_level_per_student_A, max_level_per_student_B)\n",
    "print(f\"T-test : p-value = {t_test.pvalue}\")\n",
    "\n",
    "# Mann-Whitney U for independent groups\n",
    "mann_whitney_test = stats.mannwhitneyu(max_level_per_student_A, max_level_per_student_B)\n",
    "print(f\"Mann-Whitney U test: p-value = {mann_whitney_test.pvalue}\")\n",
    "\n",
    "# Difference percentage\n",
    "diff_percent = (average_max_level_A - average_max_level_B) / average_max_level_B\n",
    "print(f\"Difference in percentage: {diff_percent}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4) (A group) Help asked to the tutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Group - Average help asked to the tutor : 22.59259259259259\n",
      "A Group - Total help asked to the tutor : 610\n"
     ]
    }
   ],
   "source": [
    "# Filter the rows where _activity is \"help\" and _type is \"asked\"\n",
    "help_requests_data = students_A_interaction_data[(students_A_interaction_data[OBJECT_ID_DATA_KEY] == HELP) &\n",
    "                                     (students_A_interaction_data[TYPE_DATA_KEY] == ASKED_TYPE)]\n",
    "# Get the total number of help requests\n",
    "total_help_requests = help_requests_data.shape[0]\n",
    "\n",
    "# Group by student and count the number of help requests\n",
    "help_requests_per_student = help_requests_data.groupby(STUDENT_DATA_KEY).size()\n",
    "\n",
    "# Calculate the average number of help requests per student\n",
    "average_help_requests = help_requests_per_student.mean()\n",
    "\n",
    "print(\"A Group - Average help asked to the tutor : \"+str(average_help_requests))\n",
    "\n",
    "print(\"A Group - Total help asked to the tutor : \"+str(total_help_requests))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5) (A group) Help given by the tutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A group - Average received help for each type:\n",
      "_object_id\n",
      "https://py-rates.org/xAPI/activities/helps/ask-teacher       6.923077\n",
      "https://py-rates.org/xAPI/activities/helps/control           3.666667\n",
      "https://py-rates.org/xAPI/activities/helps/implementation    6.782609\n",
      "https://py-rates.org/xAPI/activities/helps/notion            5.269231\n",
      "https://py-rates.org/xAPI/activities/helps/solution          3.272727\n",
      "dtype: float64\n",
      "A group - Total received help :611\n",
      "A group - Percentage of helps by types:\n",
      "_object_id\n",
      "https://py-rates.org/xAPI/activities/helps/ask-teacher       29.508197\n",
      "https://py-rates.org/xAPI/activities/helps/control           10.819672\n",
      "https://py-rates.org/xAPI/activities/helps/implementation    25.573770\n",
      "https://py-rates.org/xAPI/activities/helps/notion            22.459016\n",
      "https://py-rates.org/xAPI/activities/helps/solution          11.803279\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filter the rows where _type is \"received\" and _object_id matches one of the help types\n",
    "help_received_data = students_interaction_data[\n",
    "    (students_interaction_data[TYPE_DATA_KEY] == RECEIVED_TYPE) &\n",
    "    (students_interaction_data[OBJECT_ID_DATA_KEY].isin([ASK_TEACHER_HELP, CONTROL_HELP, IMPLEMENTATION_HELP, NOTION_HELP, SOLUTION_HELP]))\n",
    "]\n",
    "\n",
    "# Get the total number of given helps\n",
    "total_help_received = help_received_data.shape[0]\n",
    "\n",
    "# Group by the help type (_object_id) and count the number of occurrences\n",
    "help_counts_by_type = help_received_data.groupby(OBJECT_ID_DATA_KEY).size()\n",
    "\n",
    "# Calculate the percentage for each help type\n",
    "help_percentage_by_type = (help_counts_by_type / total_help_requests) * 100\n",
    "\n",
    "# Group by student and help type to count how many times each help was received\n",
    "help_received_per_student = help_received_data.groupby([STUDENT_DATA_KEY, OBJECT_ID_DATA_KEY]).size()\n",
    "\n",
    "# Calculate the average number of help received per student for each type\n",
    "average_help_received_per_type = help_received_per_student.groupby(OBJECT_ID_DATA_KEY).mean()\n",
    "\n",
    "# Print the average received help for each type\n",
    "print(\"A group - Average received help for each type:\")\n",
    "print(average_help_received_per_type)\n",
    "\n",
    "print(\"A group - Total received help :\"+str(total_help_received))\n",
    "\n",
    "print(\"A group - Percentage of helps by types:\")\n",
    "print(help_percentage_by_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6) Learning general results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Group - Average general learning : 2.9285714285714284\n",
      "B Group - Average general learning : 4.407407407407407\n",
      "General learning difference between groups : -1.478835978835979\n",
      "T-test : p-value = 0.6897708495966932\n",
      "Mann-Whitney U test: p-value = 0.6976962859109155\n"
     ]
    }
   ],
   "source": [
    "# Calculate the maximum score (sum of highest possible scores per question)\n",
    "max_score_general = sum(max(answer.values()) for answer in ANSWERS_SCORES.values())\n",
    "\n",
    "# Function to calculate a normalized score for a student\n",
    "def calculate_score(student,max_score):\n",
    "    score = 0\n",
    "    for question, answer in student.items():\n",
    "        if question in ANSWERS_SCORES and answer in ANSWERS_SCORES[question]:\n",
    "            score += ANSWERS_SCORES[question][answer]\n",
    "    return round((score/max_score)*100)\n",
    "\n",
    "students_A_pre_test_data_temp = students_A_pre_test_data.copy()\n",
    "students_A_post_test_data_temp = students_A_post_test_data.copy()\n",
    "\n",
    "# Calculate pre-test scores\n",
    "students_A_pre_test_data_temp['pre_score'] = students_A_pre_test_data_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_general\n",
    ")\n",
    "\n",
    "# Calculate post-test scores\n",
    "students_A_post_test_data_temp['post_score'] = students_A_post_test_data_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_general\n",
    ")\n",
    "\n",
    "# Merge the scores into a single DataFrame\n",
    "students_A_scores = pd.merge(\n",
    "    students_A_pre_test_data_temp[['_code', 'pre_score']],\n",
    "    students_A_post_test_data_temp[['_code', 'post_score']],\n",
    "    on='_code',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Calculate the difference between pre-test and post-test scores\n",
    "students_A_scores['score_diff'] = students_A_scores['post_score'] - students_A_scores['pre_score']\n",
    "\n",
    "\n",
    "students_B_pre_test_data_temp = students_B_pre_test_data.copy()\n",
    "students_B_post_test_data_temp = students_B_post_test_data.copy()\n",
    "\n",
    "# Calculate pre-test scores\n",
    "students_B_pre_test_data_temp['pre_score'] = students_B_pre_test_data_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_general\n",
    ")\n",
    "\n",
    "# Calculate post-test scores\n",
    "students_B_post_test_data_temp['post_score'] = students_B_post_test_data_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_general\n",
    ")\n",
    "\n",
    "# Merge the scores into a single DataFrame based on `_code`\n",
    "students_B_scores = pd.merge(\n",
    "    students_B_pre_test_data_temp[['_code', 'pre_score']],\n",
    "    students_B_post_test_data_temp[['_code', 'post_score']],\n",
    "    on='_code',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Calculate the difference between pre-test and post-test scores\n",
    "students_B_scores['score_diff'] = students_B_scores['post_score'] - students_B_scores['pre_score']\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "# print(students_A_scores.head(30))\n",
    "# print(students_B_scores.head(30))\n",
    "\n",
    "# Export to Excel file for manual checking\n",
    "students_A_scores.to_excel(\"data/cleaned_results_A.xlsx\")\n",
    "students_B_scores.to_excel(\"data/cleaned_results_B.xlsx\")\n",
    "\n",
    "# Mean calculation\n",
    "average_learning_A = students_A_scores[\"score_diff\"].mean()\n",
    "average_learning_B = students_B_scores[\"score_diff\"].mean()\n",
    "print(\"A Group - Average general learning : \"+str(average_learning_A))\n",
    "print(\"B Group - Average general learning : \"+str(average_learning_B))\n",
    "print(\"General learning difference between groups : \"+str(average_learning_A-average_learning_B))\n",
    "\n",
    "# T-test for independent groups \n",
    "t_test = stats.ttest_ind(students_A_scores[\"score_diff\"], students_B_scores[\"score_diff\"])\n",
    "print(f\"T-test : p-value = {t_test.pvalue}\")\n",
    "\n",
    "# Mann-Whitney U for independent groups\n",
    "mann_whitney_test = stats.mannwhitneyu(students_A_scores[\"score_diff\"], students_B_scores[\"score_diff\"])\n",
    "print(f\"Mann-Whitney U test: p-value = {mann_whitney_test.pvalue}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7) Learning results by notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data for different notions\n",
    "\n",
    "students_A_pre_test_data_var = students_A_pre_test_data[[CODE_DATA_KEY]+VAR_NOTION_QUESTIONS]\n",
    "students_B_pre_test_data_var = students_B_pre_test_data[[CODE_DATA_KEY]+VAR_NOTION_QUESTIONS]\n",
    "students_A_post_test_data_var = students_A_post_test_data[[CODE_DATA_KEY]+VAR_NOTION_QUESTIONS]\n",
    "students_B_post_test_data_var = students_B_post_test_data[[CODE_DATA_KEY]+VAR_NOTION_QUESTIONS]\n",
    "\n",
    "students_A_pre_test_data_for_loop = students_A_pre_test_data[[CODE_DATA_KEY]+FOR_LOOP_NOTION_QUESTIONS]\n",
    "students_B_pre_test_data_for_loop = students_B_pre_test_data[[CODE_DATA_KEY]+FOR_LOOP_NOTION_QUESTIONS]\n",
    "students_A_post_test_data_for_loop = students_A_post_test_data[[CODE_DATA_KEY]+FOR_LOOP_NOTION_QUESTIONS]\n",
    "students_B_post_test_data_for_loop = students_B_post_test_data[[CODE_DATA_KEY]+FOR_LOOP_NOTION_QUESTIONS]\n",
    "\n",
    "students_A_pre_test_data_cond = students_A_pre_test_data[[CODE_DATA_KEY]+COND_NOTION_QUESTIONS]\n",
    "students_B_pre_test_data_cond = students_B_pre_test_data[[CODE_DATA_KEY]+COND_NOTION_QUESTIONS]\n",
    "students_A_post_test_data_cond = students_A_post_test_data[[CODE_DATA_KEY]+COND_NOTION_QUESTIONS]\n",
    "students_B_post_test_data_cond = students_B_post_test_data[[CODE_DATA_KEY]+COND_NOTION_QUESTIONS]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Group - Average variable notion learning : 7.428571428571429\n",
      "B Group - Average variable notion learning : 9.037037037037036\n",
      "Variable notion learning difference between groups : -1.6084656084656075\n",
      "T-test : p-value = 0.806366779804896\n",
      "Mann-Whitney U test: p-value = 0.708690017104114\n"
     ]
    }
   ],
   "source": [
    "# Calculate the maximum score (sum of highest possible scores per question)\n",
    "max_score_var = sum(max(ANSWERS_SCORES_GRADUATED[question].values()) for question in VAR_NOTION_QUESTIONS)\n",
    "\n",
    "students_A_pre_test_data_var_temp = students_A_pre_test_data_var.copy()\n",
    "students_A_post_test_data_var_temp = students_A_post_test_data_var.copy()\n",
    "\n",
    "# Calculate pre-test scores\n",
    "students_A_pre_test_data_var_temp['pre_score'] = students_A_pre_test_data_var_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_var\n",
    ")\n",
    "\n",
    "# Calculate post-test scores\n",
    "students_A_post_test_data_var_temp['post_score'] = students_A_post_test_data_var_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_var\n",
    ")\n",
    "\n",
    "# Merge the scores into a single DataFrame\n",
    "students_A_scores_var = pd.merge(\n",
    "    students_A_pre_test_data_var_temp[['_code', 'pre_score']],\n",
    "    students_A_post_test_data_var_temp[['_code', 'post_score']],\n",
    "    on='_code',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Calculate the difference between pre-test and post-test scores\n",
    "students_A_scores_var['score_diff'] = students_A_scores_var['post_score'] - students_A_scores_var['pre_score']\n",
    "\n",
    "\n",
    "students_B_pre_test_data_var_temp = students_B_pre_test_data_var.copy()\n",
    "students_B_post_test_data_var_temp = students_B_post_test_data_var.copy()\n",
    "\n",
    "# Calculate pre-test scores\n",
    "students_B_pre_test_data_var_temp['pre_score'] = students_B_pre_test_data_var_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_var\n",
    ")\n",
    "\n",
    "# Calculate post-test scores\n",
    "students_B_post_test_data_var_temp['post_score'] = students_B_post_test_data_var_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_var\n",
    ")\n",
    "\n",
    "# Merge the scores into a single DataFrame\n",
    "students_B_scores_var = pd.merge(\n",
    "    students_B_pre_test_data_var_temp[['_code', 'pre_score']],\n",
    "    students_B_post_test_data_var_temp[['_code', 'post_score']],\n",
    "    on='_code',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Calculate the difference between pre-test and post-test scores\n",
    "students_B_scores_var['score_diff'] = students_B_scores_var['post_score'] - students_B_scores_var['pre_score']\n",
    "\n",
    "average_learning_A_var = students_A_scores_var[\"score_diff\"].mean()\n",
    "average_learning_B_var = students_B_scores_var[\"score_diff\"].mean()\n",
    "print(\"A Group - Average variable notion learning : \"+str(average_learning_A_var))\n",
    "print(\"B Group - Average variable notion learning : \"+str(average_learning_B_var))\n",
    "print(\"Variable notion learning difference between groups : \"+str(average_learning_A_var-average_learning_B_var))\n",
    "# T-test for independent groups \n",
    "t_test = stats.ttest_ind(students_A_scores_var[\"score_diff\"], students_B_scores_var[\"score_diff\"])\n",
    "print(f\"T-test : p-value = {t_test.pvalue}\")\n",
    "\n",
    "# Mann-Whitney U for independent groups\n",
    "mann_whitney_test = stats.mannwhitneyu(students_A_scores_var[\"score_diff\"], students_B_scores_var[\"score_diff\"])\n",
    "print(f\"Mann-Whitney U test: p-value = {mann_whitney_test.pvalue}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loop notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Group - Average for loop notion learning : -6.321428571428571\n",
      "B Group - Average for loop notion learning : -7.444444444444445\n",
      "For loop notion learning difference between groups : 1.1230158730158735\n",
      "T-test : p-value = 0.8783289475291471\n",
      "Mann-Whitney U test: p-value = 0.9189726848190887\n"
     ]
    }
   ],
   "source": [
    "# Calculate the maximum score (sum of highest possible scores per question)\n",
    "max_score_for_loop = sum(max(ANSWERS_SCORES_GRADUATED[question].values()) for question in FOR_LOOP_NOTION_QUESTIONS)\n",
    "\n",
    "students_A_pre_test_data_for_loop_temp = students_A_pre_test_data_for_loop.copy()\n",
    "students_A_post_test_data_for_loop_temp = students_A_post_test_data_for_loop.copy()\n",
    "\n",
    "# Calculate pre-test scores\n",
    "students_A_pre_test_data_for_loop_temp['pre_score'] = students_A_pre_test_data_for_loop_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_for_loop\n",
    ")\n",
    "\n",
    "# Calculate post-test scores\n",
    "students_A_post_test_data_for_loop_temp['post_score'] = students_A_post_test_data_for_loop_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_for_loop\n",
    ")\n",
    "\n",
    "# Merge the scores into a single DataFrame\n",
    "students_A_scores_for_loop = pd.merge(\n",
    "    students_A_pre_test_data_for_loop_temp[['_code', 'pre_score']],\n",
    "    students_A_post_test_data_for_loop_temp[['_code', 'post_score']],\n",
    "    on='_code',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Calculate the difference between pre-test and post-test scores\n",
    "students_A_scores_for_loop['score_diff'] = students_A_scores_for_loop['post_score'] - students_A_scores_for_loop['pre_score']\n",
    "\n",
    "\n",
    "students_B_pre_test_data_for_loop_temp = students_B_pre_test_data_for_loop.copy()\n",
    "students_B_post_test_data_for_loop_temp = students_B_post_test_data_for_loop.copy()\n",
    "\n",
    "# Calculate pre-test scores\n",
    "students_B_pre_test_data_for_loop_temp['pre_score'] = students_B_pre_test_data_for_loop_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_for_loop\n",
    ")\n",
    "\n",
    "# Calculate post-test scores\n",
    "students_B_post_test_data_for_loop_temp['post_score'] = students_B_post_test_data_for_loop_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_for_loop\n",
    ")\n",
    "\n",
    "# Merge the scores into a single DataFrame\n",
    "students_B_scores_for_loop = pd.merge(\n",
    "    students_B_pre_test_data_for_loop_temp[['_code', 'pre_score']],\n",
    "    students_B_post_test_data_for_loop_temp[['_code', 'post_score']],\n",
    "    on='_code',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Calculate the difference between pre-test and post-test scores\n",
    "students_B_scores_for_loop['score_diff'] = students_B_scores_for_loop['post_score'] - students_B_scores_for_loop['pre_score']\n",
    "\n",
    "average_learning_A_for_loop = students_A_scores_for_loop[\"score_diff\"].mean()\n",
    "average_learning_B_for_loop = students_B_scores_for_loop[\"score_diff\"].mean()\n",
    "print(\"A Group - Average for loop notion learning : \"+str(average_learning_A_for_loop))\n",
    "print(\"B Group - Average for loop notion learning : \"+str(average_learning_B_for_loop))\n",
    "print(\"For loop notion learning difference between groups : \"+str(average_learning_A_for_loop-average_learning_B_for_loop))\n",
    "# T-test for independent groups \n",
    "t_test = stats.ttest_ind(students_A_scores_for_loop[\"score_diff\"], students_B_scores_for_loop[\"score_diff\"])\n",
    "print(f\"T-test : p-value = {t_test.pvalue}\")\n",
    "\n",
    "# Mann-Whitney U for independent groups\n",
    "mann_whitney_test = stats.mannwhitneyu(students_A_scores_for_loop[\"score_diff\"], students_B_scores_for_loop[\"score_diff\"])\n",
    "print(f\"Mann-Whitney U test: p-value = {mann_whitney_test.pvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Group - Average conditional notion learning : 7.5\n",
      "B Group - Average conditional notion learning : 11.88888888888889\n",
      "Conditional notion learning difference between groups : -4.388888888888889\n",
      "T-test : p-value = 0.45429951932353496\n",
      "Mann-Whitney U test: p-value = 0.4570066292403503\n"
     ]
    }
   ],
   "source": [
    "# Calculate the maximum score (sum of highest possible scores per question)\n",
    "max_score_cond = sum(max(ANSWERS_SCORES_GRADUATED[question].values()) for question in COND_NOTION_QUESTIONS)\n",
    "\n",
    "students_A_pre_test_data_cond_temp = students_A_pre_test_data_cond.copy()\n",
    "students_A_post_test_data_cond_temp = students_A_post_test_data_cond.copy()\n",
    "\n",
    "# Calculate pre-test scores\n",
    "students_A_pre_test_data_cond_temp['pre_score'] = students_A_pre_test_data_cond_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_cond\n",
    ")\n",
    "\n",
    "# Calculate post-test scores\n",
    "students_A_post_test_data_cond_temp['post_score'] = students_A_post_test_data_cond_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_cond\n",
    ")\n",
    "\n",
    "# Merge the scores into a single DataFrame\n",
    "students_A_scores_cond = pd.merge(\n",
    "    students_A_pre_test_data_cond_temp[['_code', 'pre_score']],\n",
    "    students_A_post_test_data_cond_temp[['_code', 'post_score']],\n",
    "    on='_code',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Calculate the difference between pre-test and post-test scores\n",
    "students_A_scores_cond['score_diff'] = students_A_scores_cond['post_score'] - students_A_scores_cond['pre_score']\n",
    "\n",
    "\n",
    "students_B_pre_test_data_cond_temp = students_B_pre_test_data_cond.copy()\n",
    "students_B_post_test_data_cond_temp = students_B_post_test_data_cond.copy()\n",
    "\n",
    "# Calculate pre-test scores\n",
    "students_B_pre_test_data_cond_temp['pre_score'] = students_B_pre_test_data_cond_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_cond\n",
    ")\n",
    "\n",
    "# Calculate post-test scores\n",
    "students_B_post_test_data_cond_temp['post_score'] = students_B_post_test_data_cond_temp.apply(\n",
    "    calculate_score, axis=1, max_score=max_score_cond\n",
    ")\n",
    "\n",
    "# Merge the scores into a single DataFrame\n",
    "students_B_scores_cond = pd.merge(\n",
    "    students_B_pre_test_data_cond_temp[['_code', 'pre_score']],\n",
    "    students_B_post_test_data_cond_temp[['_code', 'post_score']],\n",
    "    on='_code',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Calculate the difference between pre-test and post-test scores\n",
    "students_B_scores_cond['score_diff'] = students_B_scores_cond['post_score'] - students_B_scores_cond['pre_score']\n",
    "\n",
    "average_learning_A_cond = students_A_scores_cond[\"score_diff\"].mean()\n",
    "average_learning_B_cond = students_B_scores_cond[\"score_diff\"].mean()\n",
    "print(\"A Group - Average conditional notion learning : \"+str(average_learning_A_cond))\n",
    "print(\"B Group - Average conditional notion learning : \"+str(average_learning_B_cond))\n",
    "print(\"Conditional notion learning difference between groups : \"+str(average_learning_A_cond-average_learning_B_cond))\n",
    "# T-test for independent groups \n",
    "t_test = stats.ttest_ind(students_A_scores_cond[\"score_diff\"], students_B_scores_cond[\"score_diff\"])\n",
    "print(f\"T-test : p-value = {t_test.pvalue}\")\n",
    "\n",
    "# Mann-Whitney U for independent groups\n",
    "mann_whitney_test = stats.mannwhitneyu(students_A_scores_cond[\"score_diff\"], students_B_scores_cond[\"score_diff\"])\n",
    "print(f\"Mann-Whitney U test: p-value = {mann_whitney_test.pvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8) (A group) Qualitatives aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you find the tutor helps useful to progress in the game? (0 to 100)\n",
      "Average score: 61.857142857142854\n",
      "Would you like to have this kind of help again in the future? (0 to 100)\n",
      "Average score: 76.82142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"Did you find the tutor helps useful to progress in the game? (0 to 100)\")\n",
    "print(\"Average score: \"+str(students_A_post_test_data[QA_ROW].mean()))\n",
    "\n",
    "print(\"Would you like to have this kind of help again in the future? (0 to 100)\")\n",
    "print(\"Average score: \"+str(students_A_post_test_data[QB_ROW].mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
